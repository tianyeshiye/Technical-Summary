spark  调优

关键看 spark ui 的执行结果，能看出很多问题
1、资源，并行度
2、数据本地化调优
3、数据倾斜
4、尽量避免引起shuffle 的算子
5、尽量减少jvm 的 full 垃圾回收 


做了哪些贡献 主要工作
1  复写了 hdfs 的 inputformart 和 outpputformart
2  逻辑问题，数据分情况分组的转换，一个车的信息输出到了不同的文件里面，  解决了做到一体化的逻辑问题
3   hdfs 文件的add 解决方案


--- Spark shuffle操作的具体步骤
答： 

--- 简单说一下hadoop和spark的shuffle过程？ 
答：  hadoop：map端保存分片数据，通过网络收集到reduce端。 
spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor。 
减少shuffle可以提高性能。


--- DAG，
答： DAG，有向无环图，Directed Acyclic Graph的缩写，常用于建模。
Spark中使用DAG对RDD的关系进行建模，描述了RDD的依赖关系，
这种关系也被称之为lineage，RDD的依赖关系使用Dependency维护，
参考Spark RDD之Dependency，DAG在Spark中的对应的实现为DAGScheduler。
--------------------- 
原文：https://blog.csdn.net/u011564172/article/details/70172060 


--- DAGScheduler作用
答： 1、 compute DAG，执行DAG，得到stage和对应的task，通过TaskScheduler提交到集群，流程大致如下
    2、 preferred locations，就近执行。
    3、 fault-tolerant，stage级别的容错

https://blog.csdn.net/u011564172/article/details/70172060

--- Spark Shuffle概述
答： 
https://blog.csdn.net/u011564172/article/details/71170221

--- Spark工作的一个流程
SparkContext  ->  DAGScheduler  -> stage -> taskset -> taskScheduler


答： 用户提交一个任务。 入口是从sc开始的。 
sc会去创建一个taskScheduler。根据不同的提交模式， 会根据相应的taskchedulerImpl进行任务调度。
同时会去创建Scheduler和DAGScheduler。DAGScheduler 会根据RDD的宽依赖或者窄依赖，进行阶段的划分。划分好后放入taskset中，交给taskscheduler 。
appclient会到master上注册。首先会去判断数据本地化，尽量选最好的本地化模式去执行。
打散 Executor选择相应的Executor去执行。ExecutorRunner会去创建CoarseGrainerExecutorBackend进程。 通过线程池的方式去执行任务。

--- 

--- driver的功能是什么
1、 生成SparkContext的实例
2、 作业解析
3、 作业调度
1）一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext的实例，是程序的人口点；
2）功能：负责向集群申请资源，向master注册信息，负责了作业的调度，，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler
--------------------- 


--- App中为什么会有多个job
spark用户提交的任务成为application，一个application对应一个sparkcontext，
app中存在多个job，每触发一次action操作就会产生一个job。
这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，
每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，
executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算


---  RDD机制
dd分布式弹性数据集，简单的理解成一种数据结构，是spark框架上的通用货币。 
所有算子都是基于rdd来执行的，不同的场景会有不同的rdd实现类，但是都可以进行互相转换。 
rdd执行过程中会形成dag图，然后形成lineage保证容错性等。 
从物理的角度来看rdd存储的是block和node之间的映射


--- spark工作机制

1、用户在client端提交作业后，
2、会由Driver运行main方法并创建spark context上下文。 执行add算子，形成dag图输入DAGScheduler，
3、按照RDD之间的依赖关系划分stage输入task scheduler。 
4、task scheduler会将stage划分为task set分发到各个节点的executor中执行


--- spark的优化怎么做
1）平台层面的调优  
2）应用程序层面的调优
3）JVM层面的调优

--- 什么是RDD宽依赖和窄依赖
1）窄依赖指的是每一个parent RDD的Partition最多被子RDD的一个Partition使用
2）宽依赖指的是多个子RDD的Partition会依赖同一个parent RDD的Partition

--- spark-submit的时候如何引入外部jar包
方法一：spark-submit –jars
方法二：extraClassPath spark-default中设定参数

--- RDD有哪些缺陷
1）不支持细粒度的写和更新操作（如网络爬虫），spark写数据是粗粒度的
所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是
说可以一条条的读
2）不支持增量迭代计算，Flink支持

--- Spark的数据本地性有哪几种
PROCESS_LOCAL>NODE_LOCAL>ANY

--- Spark Streaming 访问Kafka时，每次流结束后都会有一段时间间隔，执行的是什么
    streming逻辑结束后没有，流没有立马结束执行，在log中会有几秒的空白时间,为什么？

---  Spark程序执行，有时候默认为什么会产生很多task，怎么修改默认task执行个数？
1）因为输入数据有很多task，尤其是有很多小文件的时候，有多少个输入block就会有多少个task启动
2）spark中有partition的概念，每个partition都会对应一个task，task越多
3）参数可以通过spark_home/conf/spark-default.conf配置文件设置:
spark.sql.shuffle.partitions 50 spark.default.parallelism 10
第一个是针对spark sql的task数量
第二个是非spark sql程序设置生效


--- 你如何从Kafka中获取数据
基于Direct的方式
这种新的不基于Receiver的直接方式，是在Spark 1.3中引入的，从而能够确保更加健壮的机制。
替代掉使用Receiver来接收数据后，这种方式会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。
当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据


--- Spark中数据的位置是被谁管理的
每个数据分片都对应具体物理位置，数据的位置是被blockManager，无论
数据是在磁盘，内存还是tacyan，都是由blockManager管理

--- rdd有几种操作类型
1）transformation，
2）action
3）cronroller，crontroller是控制算子,
4）cache,persist，对性能和效率的有很好的支持

--- 列举你常用的action
collect，reduce,take,
count,
saveAsTextFile

--- Spark为什么要持久化，一般什么场景下要进行persist操作
spark所有复杂一点的算法都会有persist身影,spark默认数据放在内存，spark很多内容都是放在内存的，非常适合高速迭代，1000个步骤
只有第一个输入数据，中间不产生临时数据，但分布式系统风险很高，所以容易出错，就要容错，rdd出错或者分片可以根据血统算出来，如果没有对父rdd进行persist 或者cache的化，就需要重头做。
以下场景会使用persist
1）某个步骤计算非常耗时，需要进行persist持久化
2）计算链条非常长，重新恢复要算很多步骤，很好使，persist
3）checkpoint所在的rdd要持久化persist，
lazy级别，框架发现有checnkpoint，checkpoint时单独触发一个job，需要重算一遍，checkpoint前
要持久化，写个rdd.cache或者rdd.persist，将结果保存起来，再写checkpoint操作，这样执行起来会非常快，不需要重新计算rdd链条了。checkpoint之前一定会进行persist。
4）shuffle之后为什么要persist，shuffle要进性网络传输，风险很大，数据丢失重来，恢复代价很大
5）shuffle之前进行persist，框架默认将数据持久化到磁盘，这个是框架自动做的。


--- 为什么要进行序列化
序列化可以减少数据的体积，减少存储空间，
高效存储和传输数据，
不好的是使用的时候要反序列化，非常消耗CPU

--- Alluxio和Redis有什么区别
一个是分布式文件系统，一个是数据库，完全不一样的东西。
Spark可以把中间结果缓存到Tachyon上，但是不可能缓存到Redis里面吧。Redis可以做快速查询，Tachyon能做查询么？

Alluxio以内存为中心， 说白话：我们主要干的活是缓存。


--- Executor之间如何共享数据？
第三方   基于hdfs或者基于Alluxio


--- RangePartitioner分区的原理
RangePartitioner分区则尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，
也就是说一个分区中的元素肯定都是比另一个分区内的元素小或者大；但是分区内的元素是不能保证顺序的。
简单的说就是将一定范围内的数映射到某一个分区内。其原理是水塘抽样

--- Spark应用程序的执行过程是什么
1)构建Spark Application的运行环境（启动SparkContext），SparkContext向资源管理器注册并申请运行Executor资源；
2).资源管理器分配Executor资源并启动StandaloneExecutorBackend，Executor运行情况将随着心跳发送到资源管理器上；
3).SparkContext构建成DAG图，将DAG图分解成Stage，并把Taskset发送给Task Scheduler。
Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。
4).Task在Executor上运行，运行完毕释放所有资源。


--- spark.shuffle.memoryFraction参数的含义，以及优化经验
1）spark.shuffle.memoryFraction是shuffle调优中 重要参数，shuffle从上一个task拉去数据过来，
要在Executor进行聚合操作，聚合操作时使用Executor内存的比例由该参数决定，
默认是20%,如果聚合时数据超过了该大小，那么就会spill到磁盘，极大降低性能
2）如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，
提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。
此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值

--- 描述Yarn执行一个任务的过程
1）客户端client向ResouceManager提交Application，ResouceManager接受Application
并根据集群资源状况选取一个node来启动Application的任务调度器driver（ApplicationMaster）
2）ResouceManager找到那个node，命令其该node上的nodeManager来启动一个新的JVM进程运行程序的driver（ApplicationMaster）部分，driver（ApplicationMaster）启动时会首先向ResourceManager注册，说明由自己来负责当前程序的运行
3）driver（ApplicationMaster）开始下载相关jar包等各种资源，基于下载的jar等信息决定向ResourceManager申请具体的资源内容。
4）ResouceManager接受到driver（ApplicationMaster）提出的申请后，会最大化的满足资源分配请求，
并发送资源的元数据信息给driver（ApplicationMaster）；
5）driver（ApplicationMaster）收到发过来的资源元数据信息后会根据元数据信息发指令给具体机器上的NodeManager，让其启动具体的container。
6）NodeManager收到driver发来的指令，启动container，container启动后必须向driver（ApplicationMaster）注册。
7）driver（ApplicationMaster）收到container的注册，开始进行任务的调度和计算，直到任务完成。

--- Yarn中的container是由谁负责销毁的
  ApplicationMaster负责销毁

--- 不启动Spark集群Master和work服务，可不可以运行Spark程序
  可以，只要资源管理器第三方管理就可以，如由yarn管理

--- spark on yarn Cluster 模式下，ApplicationMaster和driver是在同一个进程么
是,driver 位于ApplicationMaster进程中。该进程负责申请资源，还负责监控程序、资源的动态情况

--- Spark on Yarn 模式有哪些优点
 1)与其他计算框架共享集群资源
 2)相较于Spark自带的Standalone模式，Yarn的资源分配更加细致
 3)Application部署简化
 4)Yarn通过队列的方式，管理同时运行在Yarn集群中的多个服务，可根据不同类型的应用程序负载情况，调整对应的资源使用量，实现资源弹性管理

--- 谈谈你对container的理解
  1）Container作为资源分配和调度的基本单位，其中封装了的资源如内存，CPU，磁盘，网络带宽
  2)Container由ApplicationMaster向ResourceManager申请的，由ResouceManager中的资源调度器异步分配给ApplicationMaster
  3) Container的运行是由ApplicationMaster向资源所在的NodeManager发起的，Container运行时需提供内部执行的任务命令.
  
--- Spark on Yarn架构是怎么样的
(1)ResourceManager接到请求后在集群中选择一个NodeManager分配Container，
并在Container中启动ApplicationMaster进程；
(2)在ApplicationMaster进程中初始化sparkContext；
(3)ApplicationMaster向ResourceManager申请到Container后，
通知NodeManager在获得的Container中启动excutor进程；
(4)sparkContext分配Task给excutor，excutor发送运行状态给ApplicationMaster。
https://blog.csdn.net/Kally_Wang/article/details/79699588

--- 列出你所知道的调度器，说明其工作原理
  a) Fifo schedular 默认的调度器  先进先出
  b) Capacity schedular  计算能力调度器  选择占用内存小  优先级高的
  c) Fair schedular 调肚脐  公平调度器  所有job 占用相同资源

--- spark.driver.extraJavaOptions这个参数是什么意思，你们生产环境配了多少
   传递给executors的JVM选项字符串
   
--- 你认为/etc/hosts配置错误，会对集群有什么影响
    1）直接导致域名没法解析，主节点与子节点，子节点与子节点没法正常通讯
    2）间接导致配置错误的相关节点删的服务不正常，甚至没法启动，job执行失败等等


--- hadoop的TextInputFormat作用是什么，如何自定义实现
   1，是getSplits
   2，是getRecordReader

---  为什么要用flume导入hdfs，hdfs的构架是怎样的
   flume可以实时的导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候会形成一个文件，或者超过指定时间的话也形成一个文件

--- Hive中存放是什么
   表（数据+元数据）。 存的是和hdfs的映射关系，hive是逻辑上的数据仓库，实际操作的都是hdfs上的文件，
   HQL就是用sql语法来写的mr程序。

--- Sqoop工作原理是什么
    hadoop生态圈上的数据传输工具


--- Hadoop平台集群配置、环境变量设置
   zookeeper：修改zoo.cfg文件，配置dataDir，和各个zk节点的server地址端口，tickTime心跳时间默认是2000ms，其他超时的时间都是以这个为基础的整数倍，之后再dataDir对应目录下写入myid文件和zoo.cfg中的server相对应。
   hadoop：修改 
  hadoop-env.sh配置java环境变量 
  core-site.xml配置zk地址，临时目录等 
  hdfs-site.xml配置nn信息，rpc和http通信地址，nn自动切换、zk连接超时时间等 
  yarn-site.xml配置resourcemanager地址 
  mapred-site.xml配置使用yarn 

hbase：修改 
hbase-env.sh配置java环境变量和是否使用自带的zk 
hbase-site.xml配置hdfs上数据存放路径，zk地址和通讯超时时间、master节点 
regionservers配置各个region节点 
spark：
修改spark-env.sh配置环境变量和master和worker节点配置信息

--- Hadoop性能调优
调优可以通过系统配置、程序编写和作业调度算法来进行

--- hadoop和spark的都是并行计算，那么他们有什么相同和区别
spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错。

--- kafka工作原理
producer向broker发送事件，consumer从broker消费事件。 
事件由topic区分开，每个consumer都会属于一个group。 
相同group中的consumer不能重复消费事件，而同一事件将会发送给每个不同group的consumer


--- Zookeeper为HBase
Zookeeper为HBase提供了稳定服务和failover机制
Zookeeper也避免了HMaster的 单点问题
Zookeeper管理是一个开源项目，提供服务，如维护配置信息，命名，提供分布式同步等
HMaster通过Zookeeper来追踪HRegion Server的状态。
https://www.cnblogs.com/yanzibuaa/p/7521624.html

--- JournalNode
新HDFS采用了一种共享机制，Quorum Journal Node（JournalNode）集群或者Nnetwork File System（NFS）进行共享
NFS是操作系统层面的，JournalNode是hadoop层面的，我们这里使用JournalNode集群进行数据共享（这也是主流的做法）
两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信

--- Hadoop　ZooKeeper
对于HA集群而言，确保同一时刻只有一个NameNode处于active状态是至关重要的。否则，两个NameNode的数据状态就会产生分歧，可能丢失数据，或者产生错误的结果。为了保证这点，这就需要利用使用ZooKeeper了。首先HDFS集群中的两个NameNode都在ZooKeeper中注册，当active状态的NameNode出故障时，ZooKeeper能检测到这种情况，它就会自动把standby状态的NameNode切换为active状态。

--- spark工作机制
用户在client端提交作业后，会由Driver运行main方法并创建spark context上下文。 
执行add算子，形成dag图输入dagscheduler，按照add之间的依赖关系划分stage输入task scheduler。 
task scheduler会将stage划分为task set分发到各个节点的executor中执行。


--- 

--- 

--- 

--- 

--- 

--- 




--- Combiner 和partition的作用 
  ？？？？？？？？？？？
    combine分为map端和reduce端，作用是把同一个key的键值对合并在一起 ， 这个合并的目的是为了减少网络传输
    partition是分割map每个节点的结果，按照key分别映射给不同的reduce，也是可以自定义的。这里其实可以理解归类



--- Receiver的直接方式,offset存儲在哪裏？
基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中。
Spark自己一定是同步的，因此可以保证数据是消费一次且仅消费一次。由于数据消费偏移量是保存在checkpoint中，
因此，如果后续想使用kafka高级API消费数据，需要手动的更新zookeeper中的偏移量


--- RDD通过Linage（记录数据更新）的方式为何很高效?
?????????????



答： 怀疑是Kafka 的offset的保存
？？？？


---  Spark中数据的位置是被谁管理的
？？？


https://www.cnblogs.com/itboys/p/9226658.html
https://www.cnblogs.com/itboys/p/9226479.html


https://blog.csdn.net/qq595662096/article/details/81177744
https://blog.csdn.net/m0_37803704/article/details/80366240
https://blog.csdn.net/qiezikuaichuan/article/details/51692296
https://blog.csdn.net/lijiaqi0612/article/details/79384594

https://blog.csdn.net/FisherWang_CN/article/details/80336366
