--- Spark shuffle操作的具体步骤
答： 

--- 简单说一下hadoop和spark的shuffle过程？ 
答：  hadoop：map端保存分片数据，通过网络收集到reduce端。 
spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor。 
减少shuffle可以提高性能。


--- DAG，
答： DAG，有向无环图，Directed Acyclic Graph的缩写，常用于建模。
Spark中使用DAG对RDD的关系进行建模，描述了RDD的依赖关系，
这种关系也被称之为lineage，RDD的依赖关系使用Dependency维护，
参考Spark RDD之Dependency，DAG在Spark中的对应的实现为DAGScheduler。
--------------------- 
原文：https://blog.csdn.net/u011564172/article/details/70172060 


--- DAGScheduler作用
答： 1、 compute DAG，执行DAG，得到stage和对应的task，通过TaskScheduler提交到集群，流程大致如下
    2、 preferred locations，就近执行。
    3、 fault-tolerant，stage级别的容错

https://blog.csdn.net/u011564172/article/details/70172060

--- Spark Shuffle概述
答： 
https://blog.csdn.net/u011564172/article/details/71170221

--- Spark工作的一个流程
SparkContext  ->  DAGScheduler  -> stage -> taskset -> taskScheduler


答： 用户提交一个任务。 入口是从sc开始的。 
sc会去创建一个taskScheduler。根据不同的提交模式， 会根据相应的taskchedulerImpl进行任务调度。
同时会去创建Scheduler和DAGScheduler。DAGScheduler 会根据RDD的宽依赖或者窄依赖，进行阶段的划分。划分好后放入taskset中，交给taskscheduler 。
appclient会到master上注册。首先会去判断数据本地化，尽量选最好的本地化模式去执行。
打散 Executor选择相应的Executor去执行。ExecutorRunner会去创建CoarseGrainerExecutorBackend进程。 通过线程池的方式去执行任务。

--- 

--- driver的功能是什么
1、 生成SparkContext的实例
2、 作业解析
3、 作业调度
1）一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext的实例，是程序的人口点；
2）功能：负责向集群申请资源，向master注册信息，负责了作业的调度，，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler
--------------------- 


--- App中为什么会有多个job
spark用户提交的任务成为application，一个application对应一个sparkcontext，
app中存在多个job，每触发一次action操作就会产生一个job。
这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，
每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，
executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算


---  RDD机制
dd分布式弹性数据集，简单的理解成一种数据结构，是spark框架上的通用货币。 
所有算子都是基于rdd来执行的，不同的场景会有不同的rdd实现类，但是都可以进行互相转换。 
rdd执行过程中会形成dag图，然后形成lineage保证容错性等。 
从物理的角度来看rdd存储的是block和node之间的映射


--- spark工作机制

1、用户在client端提交作业后，
2、会由Driver运行main方法并创建spark context上下文。 执行add算子，形成dag图输入dagscheduler，
3、按照add之间的依赖关系划分stage输入task scheduler。 
4、task scheduler会将stage划分为task set分发到各个节点的executor中执行


--- spark的优化怎么做
1）平台层面的调优  
2）应用程序层面的调优
3）JVM层面的调优

--- 什么是RDD宽依赖和窄依赖
1）窄依赖指的是每一个parent RDD的Partition最多被子RDD的一个Partition使用
2）宽依赖指的是多个子RDD的Partition会依赖同一个parent RDD的Partition

--- spark-submit的时候如何引入外部jar包
方法一：spark-submit –jars
方法二：extraClassPath spark-default中设定参数

--- RDD有哪些缺陷
1）不支持细粒度的写和更新操作（如网络爬虫），spark写数据是粗粒度的
所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是
说可以一条条的读
2）不支持增量迭代计算，Flink支持

--- Spark的数据本地性有哪几种
PROCESS_LOCAL>NODE_LOCAL>ANY



--- Spark Streaming 访问Kafka时，每次流结束后都会有一段时间间隔，执行的是什么
    streming逻辑结束后没有，流没有立马结束执行，在log中会有几秒的空白时间,为什么？

---  Spark程序执行，有时候默认为什么会产生很多task，怎么修改默认task执行个数？
1）因为输入数据有很多task，尤其是有很多小文件的时候，有多少个输入block就会有多少个task启动
2）spark中有partition的概念，每个partition都会对应一个task，task越多
3）参数可以通过spark_home/conf/spark-default.conf配置文件设置:
spark.sql.shuffle.partitions 50 spark.default.parallelism 10
第一个是针对spark sql的task数量
第二个是非spark sql程序设置生效



答： 怀疑是Kafka 的offset的保存
？？？？


---  Spark中数据的位置是被谁管理的
？？？


https://www.cnblogs.com/itboys/p/9226658.html
https://www.cnblogs.com/itboys/p/9226479.html


https://blog.csdn.net/qq595662096/article/details/81177744
https://blog.csdn.net/m0_37803704/article/details/80366240
https://blog.csdn.net/qiezikuaichuan/article/details/51692296
https://blog.csdn.net/lijiaqi0612/article/details/79384594

https://blog.csdn.net/FisherWang_CN/article/details/80336366