# ========================
# role-wide parameters
# ========================

# The name of HDFS cluster
# You should use the cluster name or NameNode's URL
#
cdh5_spark_hdfs_cluster_name: 'mycluster'

# ====================================
# Each configuration file parameters
# ====================================

# spark-defaults.conf
cdh5_spark_master: 'yarn'
cdh5_spark_logdir: '/user/spark/applicationHistory'
cdh5_assemble_jar_path: '/user/spark/share/lib'
cdh5_assemble_jar: '/user/spark/share/lib/spark-assembly.jar'

# spark-env.sh
cdh5_spark_exe_instances: '1'
cdh5_spark_exe_cores: '1'
cdh5_spark_exe_mem: '400M'
cdh5_spark_dri_mem: '400M'
#cdh5_spark_history_dir: 'hdfs://{{ cdh5_spark_hdfs_cluster_name }}/var/log/spark'

# /etc/default/spark
cdh5_spark_scala_home: '/usr/local/scala/default'
#
# /etc/spark/conf/metrics.properties
cdh5_spark_graphite_enabled: True
cdh5_spark_graphite_prefix: 'spark'
cdh5_spark_graphite_port: '2003'
